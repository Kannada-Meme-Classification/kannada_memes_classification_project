{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53e21370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66cedba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\deeks\\AppData\\Local\\Temp\\ipykernel_17956\\3004790783.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  LABEL_CSV = \"C:\\\\Users\\deeks\\\\OneDrive\\\\Desktop\\\\project\\\\memes.csv\"\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = \"C:\\\\Users\\\\deeks\\\\OneDrive\\\\Desktop\\\\project\\\\images\"\n",
    "LABEL_CSV = \"C:\\\\Users\\deeks\\\\OneDrive\\\\Desktop\\\\project\\\\memes.csv\"\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "912cd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.image_dir, row[\"image\"])  # <-- Key line\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = int(row[\"label\"])\n",
    "        return image, label\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfcbb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "transforms.Resize((224, 224)),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe2f90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MemeDataset(LABEL_CSV, IMAGE_DIR, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8056debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deeks\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\deeks\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2) # binary classification\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8d5598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 91, 1: 49})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\deeks\\AppData\\Local\\Temp\\ipykernel_17956\\1976548434.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv( \"C:\\\\Users\\deeks\\\\OneDrive\\\\Desktop\\\\project\\\\memes.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv( \"C:\\\\Users\\deeks\\\\OneDrive\\\\Desktop\\\\project\\\\memes.csv\")\n",
    "counts = Counter(df[\"label\"])\n",
    "print(counts)  # e.g., Counter({0: 110, 1: 30})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b86fcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(counts.values())\n",
    "weight_0 = total / counts[0]\n",
    "weight_1 = total / counts[1]\n",
    "\n",
    "class_weights = torch.tensor([weight_0, weight_1], dtype=torch.float).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c779f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2469c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7412\n",
      "Epoch 2, Loss: 0.7328\n",
      "Epoch 3, Loss: 0.7563\n",
      "Epoch 4, Loss: 0.7549\n",
      "Epoch 5, Loss: 0.7487\n",
      "Epoch 6, Loss: 0.7383\n",
      "Epoch 7, Loss: 0.7542\n",
      "Epoch 8, Loss: 0.7475\n",
      "Epoch 9, Loss: 0.7440\n",
      "Epoch 10, Loss: 0.7582\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader.dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "310e6dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.37      0.47        19\n",
      "           1       0.29      0.56      0.38         9\n",
      "\n",
      "    accuracy                           0.43        28\n",
      "   macro avg       0.47      0.46      0.43        28\n",
      "weighted avg       0.53      0.43      0.44        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
